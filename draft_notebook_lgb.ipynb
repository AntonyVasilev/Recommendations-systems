{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Практическое задание к уроку 6\n",
    "**Задание 1.**\n",
    "\n",
    "A) Попробуйте различные варианты генерации кандидатов. Какие из них дают наибольший recall@k ?\n",
    "- Пока пробуем отобрать 50 кандидатов (k=50)\n",
    "- Качество измеряем на data_val_matcher: следующие 6 недель после трейна\n",
    "\n",
    "Дают ли own recommendtions + top-popular лучший recall?  \n",
    "\n",
    "B)* Как зависит recall@k от k? Постройте для одной схемы генерации кандидатов эту зависимость для k = {20, 50, 100, 200, 500}  \n",
    "C)* Исходя из прошлого вопроса, как вы думаете, какое значение k является наиболее разумным?\n",
    "\n",
    "**Задание 2.**\n",
    "\n",
    "Обучите модель 2-ого уровня, при этом:\n",
    "\n",
    "- Добавьте минимум по 2 фичи для юзера, товара и пары юзер-товар\n",
    "\n",
    "- Измерьте отдельно precision@5 модели 1-ого уровня и двухуровневой модели на data_val_ranker\n",
    "\n",
    "- Вырос ли precision@5 при использовании двухуровневой модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AVasilev\\anaconda3\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit import als\n",
    "\n",
    "# Модель второго уровня\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# os.environ['MKL_NUM_THREADS'] = '1'\n",
    "\n",
    "# Написанные нами функции\n",
    "from src.metrics import precision_at_k, recall_at_k\n",
    "from src.utils import prefilter_items\n",
    "import src.features as ft\n",
    "from src.recommenders import MainRecommender\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/retail_train.csv')\n",
    "item_features = pd.read_csv('./data/product.csv')\n",
    "user_features = pd.read_csv('./data/hh_demographic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_COL = 'item_id'\n",
    "USER_COL = 'user_id'\n",
    "ACTUAL_COL = 'actual'\n",
    "\n",
    "# N = Neighbors\n",
    "N_PREDICT = 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process features dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column processing\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "item_features.rename(columns={'product_id': ITEM_COL}, inplace=True)\n",
    "user_features.rename(columns={'household_key': USER_COL }, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset for train, eval, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_MATCHER_WEEKS = 6\n",
    "VAL_RANKER_WEEKS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# берем данные для тренировки matching модели\n",
    "data_train_matcher = data[data['week_no'] < data['week_no'].max() - (VAL_MATCHER_WEEKS + VAL_RANKER_WEEKS)]\n",
    "\n",
    "# берем данные для валидации matching модели\n",
    "data_val_matcher = data[(data['week_no'] >= data['week_no'].max() - (VAL_MATCHER_WEEKS + VAL_RANKER_WEEKS)) &\n",
    "                      (data['week_no'] < data['week_no'].max() - (VAL_RANKER_WEEKS))]\n",
    "\n",
    "\n",
    "# берем данные для тренировки ranking модели\n",
    "data_train_ranker = data_val_matcher.copy()  # Для наглядности. Далее мы добавим изменения, и они будут отличаться\n",
    "\n",
    "# берем данные для теста ranking, matching модели\n",
    "data_val_ranker = data[data['week_no'] >= data['week_no'].max() - VAL_RANKER_WEEKS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем объединенный сет данных для первого уровня (матчинга)\n",
    "df_join_train_matcher = pd.concat([data_train_matcher, data_val_matcher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats_data(df_data, name_df):\n",
    "    print(name_df)\n",
    "    print(f\"Shape: {df_data.shape} Users: {df_data[USER_COL].nunique()} Items: {df_data[ITEM_COL].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_matcher\n",
      "Shape: (2108779, 12) Users: 2498 Items: 83685\n",
      "val_matcher\n",
      "Shape: (169711, 12) Users: 2154 Items: 27649\n",
      "train_ranker\n",
      "Shape: (169711, 12) Users: 2154 Items: 27649\n",
      "val_ranker\n",
      "Shape: (118314, 12) Users: 2042 Items: 24329\n"
     ]
    }
   ],
   "source": [
    "print_stats_data(data_train_matcher,'train_matcher')\n",
    "print_stats_data(data_val_matcher,'val_matcher')\n",
    "print_stats_data(data_train_ranker,'train_ranker')\n",
    "print_stats_data(data_val_ranker,'val_ranker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1004906</td>\n",
       "      <td>1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1033142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "0     2375  26984851472    1  1004906         1         1.39       364   \n",
       "1     2375  26984851472    1  1033142         1         0.82       364   \n",
       "\n",
       "   retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "0         -0.6        1631        1          0.0                0.0  \n",
       "1          0.0        1631        1          0.0                0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_matcher.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prefilter items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>n_purchases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34192</th>\n",
       "      <td>1082185</td>\n",
       "      <td>24318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54389</th>\n",
       "      <td>6534178</td>\n",
       "      <td>16233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28450</th>\n",
       "      <td>1029743</td>\n",
       "      <td>11661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24657</th>\n",
       "      <td>995242</td>\n",
       "      <td>10226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36790</th>\n",
       "      <td>1106523</td>\n",
       "      <td>8011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id  n_purchases\n",
       "34192  1082185        24318\n",
       "54389  6534178        16233\n",
       "28450  1029743        11661\n",
       "24657   995242        10226\n",
       "36790  1106523         8011"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Определю количество наиболее популярных товаров, которые составляют 90% продаж\n",
    "items_by_poprularity = data_train_matcher.groupby(by='item_id')['basket_id'].nunique(). \\\n",
    "    reset_index().sort_values(by='basket_id', ascending=False)\n",
    "items_by_poprularity.rename(columns={'basket_id': 'n_purchases'}, inplace=True)\n",
    "items_by_poprularity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18714"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchses_sum = items_by_poprularity.n_purchases.sum()\n",
    "top_90_percent_items_list = []\n",
    "purchses_commul_sum = 0\n",
    "for item, n_purchases in zip(items_by_poprularity.item_id, items_by_poprularity.n_purchases):\n",
    "    purchses_commul_sum += n_purchases\n",
    "    if (purchses_commul_sum / purchses_sum) < 0.9:\n",
    "        top_90_percent_items_list.append(item)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "n_popular = len(top_90_percent_items_list)\n",
    "n_popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decreased # items from 83685 to 18715\n"
     ]
    }
   ],
   "source": [
    "# Оставляю в датасете только 18714 товаров. Id остальных заменю на 999999\n",
    "n_items_before = data_train_matcher['item_id'].nunique()\n",
    "\n",
    "data_train_matcher = prefilter_items(data_train_matcher, item_features=item_features, \n",
    "                                     take_n_popular=n_popular)\n",
    "\n",
    "n_items_after = data_train_matcher['item_id'].nunique()\n",
    "print(f'Decreased # items from {n_items_before} to {n_items_after}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make cold-start to warm-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_matcher\n",
      "Shape: (861404, 13) Users: 2495 Items: 18715\n",
      "val_matcher\n",
      "Shape: (169615, 12) Users: 2151 Items: 27644\n",
      "train_ranker\n",
      "Shape: (169615, 12) Users: 2151 Items: 27644\n",
      "val_ranker\n",
      "Shape: (118282, 12) Users: 2040 Items: 24325\n"
     ]
    }
   ],
   "source": [
    "# ищем общих пользователей\n",
    "common_users = data_train_matcher.user_id.values\n",
    "\n",
    "data_val_matcher = data_val_matcher[data_val_matcher.user_id.isin(common_users)]\n",
    "data_train_ranker = data_train_ranker[data_train_ranker.user_id.isin(common_users)]\n",
    "data_val_ranker = data_val_ranker[data_val_ranker.user_id.isin(common_users)]\n",
    "\n",
    "print_stats_data(data_train_matcher,'train_matcher')\n",
    "print_stats_data(data_val_matcher,'val_matcher')\n",
    "print_stats_data(data_train_ranker,'train_ranker')\n",
    "print_stats_data(data_val_ranker,'val_ranker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weightings_list = ['bm25', 'tfidf']\n",
    "# model_type_list = ['als', 'bpr']\n",
    "# user_item_matrix_values = ['binary', 'sales_value', 'purchase_sum']\n",
    "# own_recommender_type_list = ['item-item', 'cosine', 'tfidf']\n",
    "# recs_type_list = ['own', 'rec', 'itm', 'usr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_dict = {\n",
    "#     'weighting': [],\n",
    "#     'model_type': [],\n",
    "#     'own_recommender_type': [],\n",
    "#     'user_item_matrix_values': [],\n",
    "#     'own_recall': [],\n",
    "#     'rec_recall': [],\n",
    "#     'itm_recall': [],\n",
    "#     'usr_recall': []\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for ui_value, weighting, model_type, own_recommender in product(\n",
    "#             user_item_matrix_values, weightings_list, model_type_list, own_recommender_type_list):\n",
    "#     base_recommender = MainRecommender(data_train_matcher, weighting=weighting, \n",
    "#                                        model_type=model_type, own_recommender_type=own_recommender, \n",
    "#                                        user_item_matrix_values=ui_value)\n",
    "#     result_dict['weighting'].append(weighting)\n",
    "#     result_dict['model_type'].append(model_type)\n",
    "#     result_dict['own_recommender_type'].append(own_recommender)\n",
    "#     result_dict['user_item_matrix_values'].append(ui_value)\n",
    "    \n",
    "#     for el in recs_type_list:\n",
    "#         res = base_recommender.evalMetrics(metric_type='recall', df_result=data_val_matcher, \n",
    "#                         target_col_name=USER_COL, recommend_model_type=el, N_PREDICT=N_PREDICT)\n",
    "#         result_dict[el + '_recall'].append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df = pd.DataFrame(result_dict)\n",
    "# result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in result_df.columns.to_list()[4:]:\n",
    "#     print(f'Best {col}:\\n{result_df.loc[np.argmax(result_df[col]), :]}')\n",
    "#     print('*' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init/train recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    }
   ],
   "source": [
    "recommender = MainRecommender(data_train_matcher, weighting='tfidf',\n",
    "                                 model_type='als', own_recommender_type='cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall@50 of matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_type_list = ['own', 'rec', 'itm', 'usr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPK_RECALL = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for el in recs_type_list:\n",
    "#     res = recommender.evalMetrics(metric_type='recall', df_result=data_val_matcher, \n",
    "#                     target_col_name=USER_COL, recommend_model_type=el, N_PREDICT=TOPK_RECALL)\n",
    "#     print(f'{el} recall: {res}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision@5 of matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPK_PRECISION = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for el in recs_type_list:\n",
    "#     res = recommender.evalMetrics(metric_type='precision', df_result=data_val_matcher, \n",
    "#                     target_col_name=USER_COL, recommend_model_type=el, N_PREDICT=TOPK_PRECISION)\n",
    "#     print(f'{el} precision: {res}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Второй этап отбора кандидатов\n",
    "Создаю датафрейм из кандидатов, отобранных на первом этапе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates = pd.DataFrame(data_train_ranker[USER_COL].unique())\n",
    "df_candidates.columns = [USER_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates['candidates'] = df_candidates[USER_COL].apply(\n",
    "                              lambda x: recommender.get_own_recommendations(x, N=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = df_candidates.apply(lambda x: pd.Series(x['candidates']), axis=1).stack(). \\\n",
    "                               reset_index(level=1, drop=True)\n",
    "df_items.name = 'item_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates = df_candidates.drop('candidates', axis=1).join(df_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2070</td>\n",
       "      <td>1029743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2070</td>\n",
       "      <td>913210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2070</td>\n",
       "      <td>1105426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2070</td>\n",
       "      <td>933067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2070</td>\n",
       "      <td>838186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id\n",
       "0     2070  1029743\n",
       "0     2070   913210\n",
       "0     2070  1105426\n",
       "0     2070   933067\n",
       "0     2070   838186"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_candidates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates\n",
      "Shape: (215100, 2) Users: 2151 Items: 17612\n"
     ]
    }
   ],
   "source": [
    "# Check warm start\n",
    "print_stats_data(df_candidates, 'candidates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2070</td>\n",
       "      <td>913210</td>\n",
       "      <td>40764912478</td>\n",
       "      <td>605</td>\n",
       "      <td>1</td>\n",
       "      <td>3.59</td>\n",
       "      <td>311</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>1900</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2070</td>\n",
       "      <td>933067</td>\n",
       "      <td>40764912478</td>\n",
       "      <td>605</td>\n",
       "      <td>2</td>\n",
       "      <td>5.00</td>\n",
       "      <td>311</td>\n",
       "      <td>-2.98</td>\n",
       "      <td>1900</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2070</td>\n",
       "      <td>838186</td>\n",
       "      <td>40764912478</td>\n",
       "      <td>605</td>\n",
       "      <td>1</td>\n",
       "      <td>3.99</td>\n",
       "      <td>311</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1900</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2070</td>\n",
       "      <td>1092937</td>\n",
       "      <td>40941467404</td>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>3.29</td>\n",
       "      <td>311</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2015</td>\n",
       "      <td>89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2070</td>\n",
       "      <td>1092937</td>\n",
       "      <td>41160132372</td>\n",
       "      <td>630</td>\n",
       "      <td>1</td>\n",
       "      <td>3.29</td>\n",
       "      <td>311</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14</td>\n",
       "      <td>91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id    basket_id  day  quantity  sales_value  store_id  \\\n",
       "0     2070   913210  40764912478  605         1         3.59       311   \n",
       "1     2070   933067  40764912478  605         2         5.00       311   \n",
       "2     2070   838186  40764912478  605         1         3.99       311   \n",
       "3     2070  1092937  40941467404  619         1         3.29       311   \n",
       "4     2070  1092937  41160132372  630         1         3.29       311   \n",
       "\n",
       "   retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "0        -0.40        1900       87          0.0                0.0  \n",
       "1        -2.98        1900       87          0.0                0.0  \n",
       "2         0.00        1900       87          0.0                0.0  \n",
       "3         0.00        2015       89          0.0                0.0  \n",
       "4         0.00          14       91          0.0                0.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_ranker = df_candidates.merge(data_train_ranker, on=[USER_COL, ITEM_COL])\n",
    "df_train_ranker.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаю вторую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender_2 = MainRecommender(df_train_ranker, weighting='tfidf',\n",
    "                                model_type='als', own_recommender_type='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "999999",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-51ce1a655dfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrecs_type_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     res = recommender_2.evalMetrics(metric_type='recall', df_result=df_train_ranker, \n\u001b[0m\u001b[0;32m      3\u001b[0m                     \u001b[0mtarget_col_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mUSER_COL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecommend_model_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_PREDICT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTOPK_RECALL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                    filter_items=False)\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{el} recall: {res}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Jupyter Notebook\\Recommendations-systems\\src\\recommenders.py\u001b[0m in \u001b[0;36mevalMetrics\u001b[1;34m(self, metric_type, df_result, target_col_name, recommend_model_type, N_PREDICT, filter_items)\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[0mresult_col_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'result_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrecommend_model_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m         result_eval = self._get_recommend_eval(result_eval, target_col_name, result_col_name,\n\u001b[0m\u001b[0;32m    351\u001b[0m                                                recommend_model_type, N_PREDICT, filter_items)\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Jupyter Notebook\\Recommendations-systems\\src\\recommenders.py\u001b[0m in \u001b[0;36m_get_recommend_eval\u001b[1;34m(self, result_eval, target_col_name, result_col_name, recommend_model_type, N_PREDICT, filter_items)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrecommend_model_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'own'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             result_eval[result_col_name] = result_eval[target_col_name].apply(\n\u001b[0m\u001b[0;32m    322\u001b[0m                 lambda x: self.get_own_recommendations(x, N=N_PREDICT))\n\u001b[0;32m    323\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mrecommend_model_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'rec'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4198\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4200\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Jupyter Notebook\\Recommendations-systems\\src\\recommenders.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrecommend_model_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'own'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             result_eval[result_col_name] = result_eval[target_col_name].apply(\n\u001b[1;32m--> 322\u001b[1;33m                 lambda x: self.get_own_recommendations(x, N=N_PREDICT))\n\u001b[0m\u001b[0;32m    323\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mrecommend_model_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'rec'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m             result_eval[result_col_name] = result_eval[target_col_name].apply(\n",
      "\u001b[1;32m~\\Jupyter Notebook\\Recommendations-systems\\src\\recommenders.py\u001b[0m in \u001b[0;36mget_own_recommendations\u001b[1;34m(self, user, N)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mown_recommender\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_similar_items_recommendation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Jupyter Notebook\\Recommendations-systems\\src\\recommenders.py\u001b[0m in \u001b[0;36m_get_recommendations\u001b[1;34m(self, user, model, N, filter_items)\u001b[0m\n\u001b[0;32m    241\u001b[0m                                                                         \u001b[0mN\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m                                                                         \u001b[0mfilter_already_liked_items\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m                                                                         \u001b[0mfilter_items\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitemid_to_id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m999999\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m                                                                         recalculate_user=False)]\n\u001b[0;32m    245\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 999999"
     ]
    }
   ],
   "source": [
    "for el in recs_type_list:\n",
    "    res = recommender_2.evalMetrics(metric_type='recall', df_result=df_train_ranker, \n",
    "                    target_col_name=USER_COL, recommend_model_type=el, N_PREDICT=TOPK_RECALL,\n",
    "                                   filter_items=False)\n",
    "    print(f'{el} recall: {res}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in recs_type_list:\n",
    "    res = recommender_2.evalMetrics(metric_type='precision', df_result=df_train_ranker, \n",
    "                    target_col_name=USER_COL, recommend_model_type=el, N_PREDICT=TOPK_PRECISION,\n",
    "                                   filter_items=False)\n",
    "    print(f'{el} precision: {res}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных для трейна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# взяли пользователей из трейна для ранжирования\n",
    "df_match_candidates = pd.DataFrame(data_train_ranker[USER_COL].unique())\n",
    "df_match_candidates.columns = [USER_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# собираем кандитатов с первого этапа (matcher)\n",
    "df_match_candidates['candidates'] = df_match_candidates[USER_COL].apply(lambda x: recommender.get_own_recommendations(x, N=N_PREDICT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match_candidates.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = df_match_candidates.apply(lambda x: pd.Series(x['candidates']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "df_items.name = 'item_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match_candidates = df_match_candidates.drop('candidates', axis=1).join(df_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match_candidates.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check warm start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_stats_data(df_match_candidates, 'match_candidates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем трейн сет для ранжирования с учетом кандидатов с этапа 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranker_train = data_train_ranker[[USER_COL, ITEM_COL]].copy()\n",
    "df_ranker_train['target'] = 1  # тут только покупки "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranker_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Не хватает нулей в датасете, поэтому добавляем наших кандитатов в качество нулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ranker_train = df_match_candidates.merge(df_ranker_train, on=[USER_COL, ITEM_COL], how='left')\n",
    "\n",
    "# чистим дубликаты\n",
    "df_ranker_train = df_ranker_train.drop_duplicates(subset=[USER_COL, ITEM_COL])\n",
    "\n",
    "df_ranker_train['target'].fillna(0, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranker_train.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranker_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготавливаем фичи для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranker_train = df_ranker_train.merge(item_features, on='item_id', how='left')\n",
    "df_ranker_train = df_ranker_train.merge(user_features, on='user_id', how='left')\n",
    "\n",
    "df_ranker_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавляю новые фичи в датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заказ товара в последних 5 покупках в виде последовательности бит (категориальная)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_5_purchases_as_bit_array = ft.get_last_5_purchases_as_bit_array(data_train_ranker, item_features)\n",
    "df_ranker_train = df_ranker_train.merge(last_5_purchases_as_bit_array, on=['item_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя сумма покупки 1 товара в каждой категории\n",
    "mean_purchase_by_department= ft.get_mean_purchase_per_item_by_department(data_train_ranker, \n",
    "                                                                      item_features)\n",
    "df_ranker_train = df_ranker_train.merge(mean_purchase_by_department[['user_id', \n",
    "                        'department', 'mean_purchase']], on=['user_id', 'department'], how='left')\n",
    "\n",
    "# Кол-во покупок в каждой категории\n",
    "num_purchases_by_department = ft.get_num_purchases_per_department(data_train_ranker, item_features)\n",
    "df_ranker_train = df_ranker_train.merge(num_purchases_by_department[['user_id', 'department', \n",
    "                                        'num_purchases']], on=['user_id', 'department'], how='left')\n",
    "\n",
    "# Доля покупок утром/днем/вечером\n",
    "user_trans_df = ft.get_proportion_of_purchases_by_times_of_day(data_train_ranker)\n",
    "df_ranker_train = df_ranker_train.merge(user_trans_df, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кол-во покупок в неделю\n",
    "week_purchases_df = ft.get_num_purchases_per_week(data_train_ranker)\n",
    "df_ranker_train = df_ranker_train.merge(week_purchases_df[['item_id', 'n_purchases_per_week']], \n",
    "                                        on=['item_id'], how='left')\n",
    "\n",
    "# Среднее кол-во покупок 1 товара в категории в неделю\n",
    "mean_n_purchases_per_week = ft.get_mean_num_purchases_per_item_dept_week(data_train_ranker, \n",
    "                                                                      item_features)\n",
    "df_ranker_train = df_ranker_train.merge(mean_n_purchases_per_week[['department', \n",
    "                                        'mean_n_purchases_per_week']], on=['department'], how='left')\n",
    "\n",
    "# (Кол-во покупок в неделю) / (Среднее кол-во покупок 1 товара в категории в неделю)\n",
    "df_ranker_train['n_purchases_div_by_mean'] = \\\n",
    "    df_ranker_train.n_purchases_per_week / df_ranker_train.mean_n_purchases_per_week\n",
    "\n",
    "# Цена\n",
    "item_price_df = ft.get_price(data_train_ranker)\n",
    "df_ranker_train = df_ranker_train.merge(item_price_df[['item_id', 'price']], \n",
    "                                        on=['item_id'], how='left')\n",
    "\n",
    "# Цена / Средняя цена товара в категории\n",
    "df_ranker_train.loc[(df_ranker_train.department == 'PRODUCE') &\n",
    "                    (df_ranker_train.price == float('Inf')), 'price'] = 0\n",
    "mean_price_by_department = ft.get_mean_price_by_department(df_ranker_train)\n",
    "df_ranker_train = df_ranker_train.merge(mean_price_by_department[['department', 'mean_price']], \n",
    "                                        on=['department'], how='left')\n",
    "df_ranker_train['price_div_by_mean_dept_price'] = df_ranker_train.price / df_ranker_train.mean_price\n",
    "df_ranker_train.drop('mean_price', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user_id - item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Кол-во покупок юзером конкретной категории в неделю) - (Среднее \n",
    "# кол-во покупок всеми юзерами конкретной категории в неделю)\n",
    "n_purchases_sub_by_mean = ft.get_num_purchases_sub_by_mean(data_train_ranker, item_features)\n",
    "df_ranker_train = df_ranker_train.merge(n_purchases_sub_by_mean[['user_id', 'department',\n",
    "        'n_purchases_sub_by_mean']], on=['user_id', 'department'], how='left')\n",
    "\n",
    "# (Кол-во покупок юзером конкретной категории в неделю) / (Среднее \n",
    "# кол-во покупок всеми юзерами конкретной категории в неделю)\n",
    "n_purchases_div_by_mean = ft.get_num_purchases_div_by_mean_all_users(data_train_ranker, item_features)\n",
    "df_ranker_train = df_ranker_train.merge(n_purchases_div_by_mean[['user_id', 'department',\n",
    "        'n_purchases_div_by_mean_all_users']], on=['user_id', 'department'], how='left')\n",
    "\n",
    "# (Средняя сумма покупки 1 товара в каждой категории (берем категорию item_id)) - (Цена item_id)\n",
    "sales_values_by_dept = ft.get_mean_sales_value_per_item_by_department(data_train_ranker, item_features)\n",
    "df_ranker_train = df_ranker_train.merge(sales_values_by_dept[['department', 'mean_sale_sum_per_item']], \n",
    "                                        on=['department'], how='left')\n",
    "df_ranker_train['mean_sale_sum_per_item_sub_price'] = \\\n",
    "    df_ranker_train.mean_sale_sum_per_item - df_ranker_train.price\n",
    "df_ranker_train.drop('mean_sale_sum_per_item', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поведенческие фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Общая сумма покупок каждого товара\n",
    "total_item_sales_value = ft.get_total_item_sales_value(df_join_train_matcher)\n",
    "df_ranker_train = df_ranker_train.merge(total_item_sales_value, how='left', on='item_id')\n",
    "\n",
    "# Общее количество по каждому товару\n",
    "total_quantity_value = ft.get_total_quantity_value(df_join_train_matcher)\n",
    "df_ranker_train = df_ranker_train.merge(total_quantity_value, how='left', on='item_id')\n",
    "\n",
    "# Количество покупателей по каждому товару\n",
    "item_freq = ft.get_item_freq(df_join_train_matcher)\n",
    "df_ranker_train = df_ranker_train.merge(item_freq, how='left', on='item_id')\n",
    "\n",
    "# Частота пользователей\n",
    "user_freq = ft.get_user_freq(df_join_train_matcher)\n",
    "df_ranker_train = df_ranker_train.merge(user_freq, how='left', on=USER_COL)\n",
    "\n",
    "# Общее количество покупок по каждому пользователю\n",
    "total_user_sales_value = ft.get_total_user_sales_value(df_join_train_matcher)\n",
    "df_ranker_train = df_ranker_train.merge(total_user_sales_value, how='left', on='user_id')\n",
    "\n",
    "# Среднее количество покупок товара в неделю\n",
    "item_quantity_per_week = ft.get_item_quantity_per_week(df_join_train_matcher)\n",
    "df_ranker_train = df_ranker_train.merge(item_quantity_per_week, how='left', on='item_id')\n",
    "\n",
    "# Среднее количество купленного товара пользователем в неделю\n",
    "user_quantity_per_week = ft.get_user_quantity_per_week(df_join_train_matcher)\n",
    "df_ranker_train = df_ranker_train.merge(user_quantity_per_week, how='left', on='user_id')\n",
    "\n",
    "# Среднее количество товара за 1 покупку\n",
    "item_quantity_per_basket = ft.get_item_quantity_per_basket(df_join_train_matcher)\n",
    "df_ranker_train = df_ranker_train.merge(item_quantity_per_basket, how='left', on='item_id')\n",
    "\n",
    "# Среднее количество товара у польователя за 1 покупку\n",
    "user_quantity_per_basket = ft.get_user_quantity_per_basket(df_join_train_matcher)\n",
    "df_ranker_train = df_ranker_train.merge(user_quantity_per_basket, how='left', on='user_id')\n",
    "\n",
    "# Средняя частота товара в карзине\n",
    "item_freq_per_basket = ft.get_item_freq_per_basket(df_join_train_matcher)\n",
    "df_ranker_train = df_ranker_train.merge(item_freq_per_basket, how='left', on='item_id')\n",
    "\n",
    "# Средняя частота пользователей купивших товар\n",
    "user_freq_per_basket = ft.get_user_freq_per_basket(df_join_train_matcher)\n",
    "df_ranker_train = df_ranker_train.merge(user_freq_per_basket, how='left', on='user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Факторы товаров из модели матричной факторизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_factors = pd.DataFrame(recommender.model.item_factors)\n",
    "# item_factors.columns = [f'item_factor_{i}' for i in range(len(item_factors.columns))]\n",
    "# item_ids = [recommender.id_to_itemid[itm_id] for itm_id in range(item_factors.shape[0])]\n",
    "# item_factors = pd.concat([pd.DataFrame(item_ids), item_factors], axis=1)\n",
    "# item_factors.rename(columns={0: 'item_id'}, inplace=True)\n",
    "# item_factors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_factors = recommender.get_item_factors()\n",
    "df_ranker_train = df_ranker_train.merge(item_factors, on=['item_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Факторы пользователей из модели матричной факторизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_factors = pd.DataFrame(recommender.model.user_factors)\n",
    "# user_factors.columns = [f'user_factor_{i}' for i in range(len(user_factors.columns))]\n",
    "# user_ids = [recommender.id_to_userid[usr_id] for usr_id in range(user_factors.shape[0])]\n",
    "# user_factors = pd.concat([pd.DataFrame(user_ids), user_factors], axis=1)\n",
    "# user_factors.rename(columns={0: 'user_id'}, inplace=True)\n",
    "# user_factors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_factors = recommender.get_user_factors()\n",
    "df_ranker_train = df_ranker_train.merge(user_factors, on=['user_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиваю на X и y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranker_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_ranker_train.drop('target', axis=1)\n",
    "y_train = df_ranker_train[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_feats = X_train.columns[2:16].tolist()\n",
    "X_train[cat_feats] = X_train[cat_feats].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели ранжирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = LGBMClassifier(objective='binary',\n",
    "                     max_depth=10,\n",
    "                     n_estimators=500,\n",
    "                     learning_rate=0.1,\n",
    "                     categorical_column=cat_feats,\n",
    "                     random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "train_preds = lgb.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranker_predict = df_ranker_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranker_predict['proba_item_purchase'] = train_preds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranker_predict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Matcher\\'s precision:')\n",
    "# for el in recs_type_list:\n",
    "#     res = recommender.evalMetrics(metric_type='precision', df_result=data_val_matcher, \n",
    "#                     target_col_name=USER_COL, recommend_model_type=el, N_PREDICT=TOPK_PRECISION)\n",
    "#     print(f'{el} precision: {res}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Ranker\\'s precision:')\n",
    "# for el in recs_type_list:\n",
    "#     res = recommender.evalMetrics(metric_type='precision', df_result=data_val_ranker, \n",
    "#                     target_col_name=USER_COL, recommend_model_type=el, N_PREDICT=TOPK_PRECISION)\n",
    "#     print(f'{el} precision: {res}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval re-ranked matched result on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Re-ranked precision:')\n",
    "recommender.reranked_metrics(metric_type='precision', df_result=data_val_ranker, \n",
    "                                  df_predict=df_ranker_predict, target_col_name=USER_COL, \n",
    "                                  recommend_model_type='own', N_PREDICT=TOPK_PRECISION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка на тесте для выполнения курсового проекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv('./data/retail_test1.csv')\n",
    "# df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warm start\n",
    "# df_test = df_test[df_test.user_id.isin(common_users)]\n",
    "# print_stats_data(df_test,'df_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Test precision:')\n",
    "# recommender.evalMetrics(metric_type='precision', df_result=df_test, \n",
    "#                 target_col_name=USER_COL, recommend_model_type='own', N_PREDICT=TOPK_PRECISION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Test re-ranked precision:')\n",
    "# recommender.reranked_metrics(metric_type='precision', df_result=df_test, \n",
    "#                                   df_predict=df_ranker_predict, target_col_name=USER_COL, \n",
    "#                                   recommend_model_type='own', N_PREDICT=TOPK_PRECISION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
